{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np\n",
    "import time \n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and initializing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sudokus(filename, sudokusize=9):\n",
    "    '''\n",
    "    get_states is to read multiple sudokus in the format:\n",
    "    ..8..4..5...64..5 etc.\n",
    "    returns a list of sudoku board states as clauses in a dict\n",
    "    '''\n",
    "    sudokus = []\n",
    "    with open(filename) as sudoku_states:\n",
    "        for i, state in enumerate(sudoku_states):\n",
    "            sudoku = {}\n",
    "            pointers = {}\n",
    "            row = 1\n",
    "            index = 0\n",
    "            for j, content in enumerate(state):\n",
    "                if j%sudokusize == 0 and j > 0:\n",
    "                    row+=1\n",
    "                try:\n",
    "                    int(content)\n",
    "                    literal = int(str(row) + str(j%sudokusize+1) + content)\n",
    "                    sudoku[index] = [literal]\n",
    "                    if literal not in pointers.keys():\n",
    "                        pointers[literal] = [index]\n",
    "                    else:\n",
    "                        pointers[literal].append(index)\n",
    "                    index += 1\n",
    "                except:\n",
    "                    # is not convertible to int\n",
    "                    continue\n",
    "            sudokus.append((sudoku, pointers))\n",
    "    return sudokus\n",
    "\n",
    "def get_constraints_from_dimacs(filename, prevConstraints={}, prevPointers={}):\n",
    "    '''\n",
    "    Convert dimacs file to a dictionary of constraints\n",
    "    and pointers. Allows merging with previous pointers and constraints.\n",
    "    '''\n",
    "    constraints = prevConstraints # dictionary with constraints as: clausenumber->[literals]\n",
    "    pointers = prevPointers # dictionary with pointers to clause numbers for literals as: literals->[clausenumbers]\n",
    "    initial_length = len(constraints)\n",
    "    with open(filename) as f:\n",
    "        for i, clause in enumerate(f):\n",
    "            index = i + initial_length\n",
    "            if clause[0] == 'c' or clause[0] == 'p':\n",
    "                # skip comments etc.\n",
    "                continue\n",
    "            constraints[index]= []\n",
    "            for literal in clause.split():\n",
    "                literal = int(literal)\n",
    "                if literal != 0:\n",
    "                    constraints[index].append(literal)\n",
    "                    if literal not in pointers.keys():\n",
    "                        pointers[literal] = [index]\n",
    "                    else:\n",
    "                        pointers[literal].append(index)\n",
    "                    \n",
    "    return constraints, pointers\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DP helper functions for constraints updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_literal(constraints, pointers, literal, assignments):\n",
    "    '''\n",
    "    assign the given literal to be True.\n",
    "    assign_literal is aimed to be one recursion stack, so deepcopies are made\n",
    "    in order to properly backtrack\n",
    "    '''\n",
    "    constraintsCopied = deepcopy(constraints)\n",
    "    pointersCopied = deepcopy(pointers)\n",
    "    assignmentsCopied = deepcopy(assignments)\n",
    "    assignmentsUpdated = update_assigments(assignmentsCopied, literal)\n",
    "    constraintsUpdated, pointersUpdated = update_constraints(constraintsCopied, pointersCopied, literal)\n",
    "    return constraintsUpdated, pointersUpdated, assignmentsUpdated\n",
    "     \n",
    "def update_constraints(constraints, pointers, literal):\n",
    "    '''\n",
    "    literal: e.g. 112 or 112'\n",
    "    Updates constraints and pointers by removing all clauses \n",
    "    with the given literal, because the clause becomes true.\n",
    "    Remove counter-literal out of all clauses.\n",
    "    '''\n",
    "    ## Find clauses with literal and remove them\n",
    "    \n",
    "    for lit in literal:\n",
    "        clauses=list(pointers[lit])\n",
    "        for clause in clauses:\n",
    "            for l in constraints[clause]:\n",
    "                pointers[l].remove(clause)\n",
    "                if len(pointers[l])==0 and l!=lit:\n",
    "                    del pointers[l]\n",
    "            del constraints[clause]\n",
    "        del pointers[lit]\n",
    "    \n",
    "    ## Find clauses with counter-literal and remove its counter-literal\n",
    "    \n",
    "    for lit in literal:\n",
    "        counterLiteral = -lit\n",
    "        if counterLiteral in pointers.keys():\n",
    "            counters=list(pointers[counterLiteral])\n",
    "            for clause in counters:\n",
    "                constraints[clause].remove(counterLiteral)\n",
    "            del pointers[counterLiteral]\n",
    "        else:\n",
    "            continue\n",
    "   \n",
    "    return constraints, pointers\n",
    "\n",
    "def update_assigments(assignments, literal):\n",
    "    '''\n",
    "    Keep track of assigned literals.\n",
    "    Needed in order to return satisfiable solution of literals.\n",
    "    '''\n",
    "    for lit in literal:\n",
    "        if lit in assignments:\n",
    "            print(\"already assigned\", lit, \"(in this stack), returning...\")\n",
    "#             return\n",
    "        else:\n",
    "            assignments.append(lit)\n",
    "    return assignments\n",
    "\n",
    "def check_tautologies(constraints, pointers):\n",
    "    '''\n",
    "    Check for clauses with a tautology and remove\n",
    "    them.\n",
    "    '''\n",
    "    foundOne = False\n",
    "    for clause in constraints.keys():\n",
    "        literals = constraints[clause]\n",
    "        counterLiterals = [-x for x in literals]\n",
    "        for i in literals:\n",
    "            for j in counterLiterals:\n",
    "                if i == j:\n",
    "                    del constraints[clause]\n",
    "                    pointers[i].remove(clause)\n",
    "                    pointers[-i].remove(clause)\n",
    "                    foundOne = True\n",
    "                    break\n",
    "    if foundOne:\n",
    "        print(\"Found tautologies and removed corresponding clauses\")\n",
    "    else:\n",
    "        print(\"No tautologies found\")\n",
    "                  \n",
    "    return constraints, pointers  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features to use as regressor datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(literals, constraints, pointers, assignments, logging=True):\n",
    "    \n",
    "    literal = next(iter(literals))\n",
    "    ## Look one step ahead\n",
    "    constraintsNew, pointersNew, assignmentsNew = assign_literal(constraints, pointers, literals, assignments)\n",
    "    \n",
    "    ## Ratio of the polarity of this literal before assignment\n",
    "    positive = len(pointers[literal])\n",
    "    negative = len(pointers[-literal])\n",
    "    total = positive+negative\n",
    "    if total != 0:\n",
    "        ratio = positive/(positive+negative)\n",
    "    else:\n",
    "        ratio = 0\n",
    "    \n",
    "    # Clauses that were resolved with this assignment\n",
    "    clausesResolved = len(constraints) - len(constraintsNew)\n",
    "    \n",
    "    # Clauses that became empty with this assignment\n",
    "    emptyClauses = 0\n",
    "    for clause in constraintsNew.keys():\n",
    "        if not constraintsNew[clause]:\n",
    "            emptyClauses += 1\n",
    "    \n",
    "    ## Average clause length with given literal before assignment\n",
    "    clauses = pointers[literal]\n",
    "    lengths = [len(constraints[c]) for c in clauses]\n",
    "    if len(lengths) != 0:\n",
    "        mean = np.mean(lengths) \n",
    "    else:\n",
    "        mean = 0\n",
    "        \n",
    "    _, momScores = mom(constraints, pointers, 1, [literal])\n",
    "    \n",
    "    _, jerowScores = jeroSloWang(constraints, pointers, [literal])\n",
    "    \n",
    "    if logging:\n",
    "        global features\n",
    "        features[literal] = {}\n",
    "        features[literal][\"posneg_ratio\"] = ratio\n",
    "        features[literal][\"c_res\"] = clausesResolved\n",
    "        features[literal][\"empty_c\"] = emptyClauses  \n",
    "        features[literal][\"c_len\"] = mean\n",
    "        features[literal][\"SAT\"] = 0\n",
    "        features[literal][\"mom\"] = next(iter(momScores))\n",
    "        features[literal][\"jerow\"] = next(iter(jerowScores))\n",
    "    else:\n",
    "        norma=norm([ratio, clausesResolved, emptyClauses, mean, next(iter(momScores)), next(iter(jerowScores))])\n",
    "        return norma\n",
    "def norm(X):\n",
    "    newX=[]\n",
    "#     print(len(X),len(X[0]))\n",
    "#     print(X)\n",
    "#     print(maxmin['posneg_ratio'][1],maxmin['posneg_ratio'][0])\n",
    "    newX.append((X[0]-maxmin['posneg_ratio'][1])/(maxmin['posneg_ratio'][0]-maxmin['posneg_ratio'][1]))\n",
    "    newX.append((X[1]-maxmin['c_res'][1])/(maxmin['c_res'][0]-maxmin['c_res'][1]))\n",
    "    newX.append(X[2])\n",
    "    newX.append((X[3]-maxmin['c_len'][1])/(maxmin['c_len'][0]-maxmin['c_len'][1]))\n",
    "    newX.append((X[4]-maxmin['mom'][1])/(maxmin['mom'][0]-maxmin['mom'][1]))\n",
    "    newX.append((X[5]-maxmin['jerow'][1])/(maxmin['jerow'][0]-maxmin['jerow'][1]))\n",
    "#     print(newX)\n",
    "    return newX\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train linear discriminant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(file=None):\n",
    "    print(\"Training logistic regressor...\")\n",
    "    df=pd.read_json(file)\n",
    "#     print(df.keys())\n",
    "    df=df[['SAT','posneg_ratio','c_res','empty_c','c_len','mom','jerow']]\n",
    "    global maxmin\n",
    "    maxmin={}\n",
    "    for col in df.keys():\n",
    "        maxmin[col]=(max(df[col]),min(df[col]))\n",
    "    toNorm=list(df.keys())\n",
    "    toNorm.remove('SAT')\n",
    "    toNorm.remove('empty_c')\n",
    "    for col in toNorm:\n",
    "        df[col]=df[col].apply(lambda x:(x-maxmin[col][1])/(maxmin[col][0]-maxmin[col][1]))\n",
    "    trainKeys=list(df.keys())\n",
    "    trainKeys.remove('SAT')\n",
    "    X = df[trainKeys]\n",
    "    y = df['SAT']\n",
    "     \n",
    "    global regressor\n",
    "    regressor = LogisticRegression().fit(np.array(X), np.array(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DP cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_clause(constraints):\n",
    "    for clause in constraints.keys():\n",
    "        if not constraints[clause]:\n",
    "            return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "def unit_clause(constraints): \n",
    "    units=[]\n",
    "    negUnit=[]\n",
    "    for clause in constraints.keys():\n",
    "        if len(constraints[clause])==1:\n",
    "            literal = constraints[clause][0]\n",
    "            if literal>0:\n",
    "                units.append(literal)\n",
    "            else:\n",
    "                negUnit.append(literal)\n",
    "    if len(units)>0:\n",
    "        return list(set(units))\n",
    "    else:\n",
    "        return list(set(negUnit))\n",
    "\n",
    "def unit_propagate(constraints, pointers, assignments):\n",
    "    '''\n",
    "    Automatically assign the literal of all unit clauses\n",
    "    until there are no unit clauses left.\n",
    "    '''\n",
    "    literals = unit_clause(constraints)\n",
    "    if len(literals)>0:\n",
    "        status=True\n",
    "        constraints, pointers, assignments = assign_literal(constraints, pointers, literals, assignments)    \n",
    "    else:\n",
    "        status=False\n",
    "    \n",
    "    return constraints, pointers, assignments,status\n",
    "\n",
    "def pure_literal(pointers):\n",
    "    literals=list(pointers.keys())\n",
    "    for literal in literals:\n",
    "        if -literal not in literals:\n",
    "            return [literal],True\n",
    "        \n",
    "    return None,False\n",
    "\n",
    "def random_literal(pointers):\n",
    "    literals=list(pointers.keys())  \n",
    "    try:\n",
    "        literal = random.choice(literals) \n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "    return [literal]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Branch split heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg(constraints, pointers, assignments, b=5): \n",
    "    '''\n",
    "    Logreg performs a prediction on a batch of literals and picks the highest scoring literal.\n",
    "    '''\n",
    "    if(len(pointers.keys()) < b):\n",
    "        b = len(pointers.keys())\n",
    "    if len(pointers.keys())==0:\n",
    "        return []\n",
    "    batch = random.sample(list(pointers.keys()), k=b)\n",
    "    X = np.array([extract_features([literal], constraints, pointers, assignments, logging=False) for literal in batch])\n",
    "    scores = regressor.predict(X) # globally available regressor\n",
    "    literal = batch[np.argmax(scores)]\n",
    "    return [literal]\n",
    "    \n",
    "#Mom's heuristic    \n",
    "def mom(constraints, pointers, k, batch=False):\n",
    "    momScores = []\n",
    "    smallestClasses=[]\n",
    "    minClass=np.inf\n",
    "    for clause in constraints.keys():\n",
    "        if len(constraints[clause])<minClass:\n",
    "            minClass=len(constraints[clause])\n",
    "            smallestClasses=[]\n",
    "            smallestClasses.append(clause)\n",
    "        elif len(constraints[clause])==minClass:\n",
    "            smallestClasses.append(clause)\n",
    "    value=0\n",
    "    maxLiteral=None\n",
    "    haveSeen=[]\n",
    "    \n",
    "    if batch:\n",
    "        b = batch\n",
    "    else:\n",
    "        b = pointers.keys()\n",
    "    \n",
    "    for literal in b:\n",
    "        if literal not in haveSeen and -literal not in haveSeen:\n",
    "            X=len([x for x in pointers[literal] if x in smallestClasses])\n",
    "            X_=len([x for x in pointers[-literal] if x in smallestClasses])\n",
    "            momsValue=(X+X_)*2^k+(X*X_)\n",
    "            momScores.append(momsValue)\n",
    "            haveSeen.append(literal)\n",
    "            if momsValue>value:\n",
    "                value=momsValue\n",
    "                maxLiteral=literal\n",
    "    if maxLiteral:\n",
    "        return [maxLiteral], momScores\n",
    "    else:\n",
    "        return [], momScores\n",
    "    \n",
    "#jeroslow wang heuristic\n",
    "def jeroSloWang(constraints, pointers, batch=False):\n",
    "    j={}\n",
    "    jerowScores = []\n",
    "    maxValue=0\n",
    "    maxLiteral=None\n",
    "    if len(pointers.keys())==0:\n",
    "        return []\n",
    "    \n",
    "    if batch:\n",
    "        b = batch\n",
    "    else:\n",
    "        b = pointers.keys()\n",
    "    \n",
    "    for literal in b:\n",
    "        for clause in pointers[literal]:\n",
    "            if literal not in j.keys():\n",
    "                j[literal]=0\n",
    "            j[literal]+=(2**(-len(constraints[clause])))\n",
    "       \n",
    "        if j[literal]>maxValue:\n",
    "            maxValue=j[literal]\n",
    "            maxLiteral=literal\n",
    "            \n",
    "    return [maxLiteral], [j[literal] for literal in batch]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DP main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DP(constraints, pointers, assignments, split): \n",
    "    '''\n",
    "    DP main recursive function. Always returns satisfiable\n",
    "    assignment for all constraints if there is one.\n",
    "    '''\n",
    "\n",
    "    status=True\n",
    "    while status:\n",
    "        constraints, pointers, assignments,status = unit_propagate(constraints, pointers, assignments)\n",
    "        \n",
    "    status=True\n",
    "    while status:\n",
    "        literal,status = pure_literal(pointers)\n",
    "        if status:\n",
    "            constraints, pointers, assignments = assign_literal(constraints, pointers, literal, assignments)\n",
    "    \n",
    "    if len(constraints.keys())==0:\n",
    "        return assignments\n",
    "   \n",
    "    if empty_clause(constraints):\n",
    "        return [] \n",
    "    \n",
    "#     batch = random.sample(list(pointers.keys()), 10)\n",
    "    \n",
    "    global assignmentCount\n",
    "    assignmentCount += 1\n",
    "    if split==\"random\":\n",
    "        literal = random_literal(pointers)\n",
    "        extract_features(literal, constraints, pointers, assignments, logging=True)\n",
    "        if len(literal)==0:\n",
    "            return DP(constraints, pointers, assignments, split)\n",
    "    if split==\"jerow\":\n",
    "        literal, scores = jeroSloWang(constraints,pointers)\n",
    "        if len(literal)==0:\n",
    "            return DP(constraints, pointers, assignments, split)\n",
    "    if split==\"moms\":\n",
    "        literal, scores = mom(constraints, pointers, 1)\n",
    "        if len(literal)==0:\n",
    "            return DP(constraints, pointers, assignments, split)\n",
    "    if split==\"logreg\":\n",
    "        literal = logreg(constraints, pointers, assignments, 10)\n",
    "        if len(literal)==0:\n",
    "            return DP(constraints, pointers, assignments, split)\n",
    "        \n",
    "    constraintsUpdated, pointersUpdated, assignmentsUpdated = assign_literal(constraints, pointers, literal, assignments)\n",
    "    assignmentsFinal = DP(constraintsUpdated, pointersUpdated, assignmentsUpdated, split)\n",
    "    if len(assignmentsFinal)>0:\n",
    "        return assignmentsFinal\n",
    "    else:\n",
    "        constraints, pointers, assignments = assign_literal(constraints, pointers, [literal[0]*-1], assignments)\n",
    "        return DP(constraints, pointers, assignments,split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training logistic regressor...\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 1 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 3 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 5 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 7 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 9 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 11 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 13 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 15 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 17 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 19 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 21 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 23 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 25 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 27 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 29 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 31 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 33 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 35 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 37 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 39 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 41 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 43 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 45 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 47 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 49 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 51 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 53 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 55 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 57 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 59 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 61 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 63 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 65 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 67 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 69 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 71 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 73 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 75 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 77 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 79 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 81 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 83 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 85 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 87 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 89 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 91 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 93 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 95 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 97 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 99 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 101 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 103 out of  500\n",
      "Reading and analyzing...\n",
      "No tautologies found\n",
      "Starting DP algorithm with logreg splits...\n",
      "this is number 105 out of  500\n",
      "Reading and analyzing...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datapoints = []\n",
    "train_sudokus = [x for x in range(0,1000) if x%2 == 0]\n",
    "test_sudokus = [x for x in range(0,1000) if x%2 == 1]\n",
    "\n",
    "\n",
    "# df.to_json(\"normalized data.json\")\n",
    "\n",
    "train('final data to train.json')\n",
    "\n",
    "run_statistics = {}\n",
    "sudokus1000 = get_sudokus('1000 sudokus.txt')\n",
    "# heuristics = [\"random\", \"moms\", \"jerow\", \"logreg\"]\n",
    "heuristics = [\"logreg\"]\n",
    "    \n",
    "## Run DP\n",
    "runs = 1\n",
    "for run in range(0, runs):\n",
    "    run_statistics[run] = {}\n",
    "    for i in test_sudokus:\n",
    "        run_statistics[run][i] = {}\n",
    "        for h in heuristics:\n",
    "            run_statistics[run][i][h] = {}\n",
    "            ## Get board and rules\n",
    "            \n",
    "            print(\"Reading and analyzing...\")\n",
    "            constraints, pointers = sudokus1000[i]\n",
    "            run_statistics[run][i][h][\"beginAssigments\"] = len(pointers)\n",
    "            constraints, pointers = get_constraints_from_dimacs('sudoku-rules.txt', constraints, pointers)\n",
    "            constraints, pointers = check_tautologies(constraints, pointers)\n",
    "\n",
    "            print(\"Starting DP algorithm with \"+ h + \" splits...\")\n",
    "            assignmentCount = 0\n",
    "            global features\n",
    "            features = {}\n",
    "            startTime = time.time()\n",
    "            assignments = DP(constraints, pointers, [], split=h)\n",
    "            endTime = time.time()\n",
    "            print(\"this is number\",i,'out of ',len(train_sudokus))\n",
    "            if assignments:\n",
    "#                 print(\"Solution found\")\n",
    "#                 print(\"Time to complete:\", \"%2f seconds\"%(endTime-startTime))\n",
    "                boardPositions = [a for a in assignments if a > 0]\n",
    "#                 print(np.reshape([int(str(pos)[2]) for pos in sorted(boardPositions)], (9,9)))\n",
    "#                 print(\"Branch split choices made:\", assignmentCount)\n",
    "                run_statistics[run][i][h][\"assignmentCount\"] = assignmentCount\n",
    "                run_statistics[run][i][h][\"runTime\"] = (endTime-startTime)\n",
    "                for a in assignments:\n",
    "                    if a in features.keys():\n",
    "                        features[a][\"SAT\"] = 1\n",
    "                for f in features.keys():\n",
    "                    datapoints.append(features[f])\n",
    "            else:\n",
    "                print(\"No solution found\")\n",
    "                \n",
    "# if datapoints:                \n",
    "#     with open('new logreg data 1 mrt.json', 'w') as outfile:\n",
    "#         json.dump(datapoints, outfile)\n",
    "\n",
    "with open('outputs log reg laatste,json', 'w') as f:\n",
    "    json.dump(run_statistics, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataTable={}\n",
    "def analyze_run(file):\n",
    "    average_time = {}\n",
    "    average_assignments = {}\n",
    "    with open(file) as f:\n",
    "        runs = json.load(f)\n",
    "        for run in runs.keys():\n",
    "            for sudoku in runs[run].keys():\n",
    "                for heuristic in runs[run][sudoku].keys():\n",
    "                    if heuristic not in average_time.keys():\n",
    "                        average_time[heuristic] = []\n",
    "                    if heuristic not in average_assignments.keys():\n",
    "                        average_assignments[heuristic] = []\n",
    "                    average_time[heuristic].append(runs[run][sudoku][heuristic][\"runTime\"])\n",
    "                    average_assignments[heuristic].append(runs[run][sudoku][heuristic][\"assignmentCount\"])\n",
    "    for h in average_time.keys():\n",
    "        dataTable[file.split('.')[0]+' time']=average_time[h][0:500]\n",
    "        dataTable[file.split('.')[0]+' assignments']=average_assignments[h][0:500]\n",
    "\n",
    "analyze_run('output moms.json')\n",
    "analyze_run('output random.json')\n",
    "# analyze_run('output log reg.json')\n",
    "analyze_run('output jerow.json')\n",
    "# analyze_run('output log not relative.json')\n",
    "analyze_run('outputs log reg laatste.json')\n",
    "df=pd.DataFrame(dataTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=['i'+str(x) for x in range(len(df))]\n",
    "df['instance']=num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['output random assignments']>=0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins={}\n",
    "for i in range(14):\n",
    "    if len(bins.keys())==0:\n",
    "        bins[str(0)+':'+str((i+1)*2)]=df[(df['output random assignments']>=0) & (df['output random assignments']<1*(i+1)*2)]['instance']\n",
    "    else:\n",
    "        bins[str(i*2)+':'+str((i+1)*2)]=df[(df['output random assignments']>=2*i) & (df['output random assignments']<1*(i+1)*2)]['instance']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['output moms assignments',\n",
    "       'output random assignments', \n",
    "       'output jerow assignments',\n",
    "       'new logreg 1 mrt assignments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "fig, ax = plt.subplots(1,figsize=(10, 10))\n",
    "\n",
    "for col in columns:#['output random assignments']:#columns:\n",
    "    x=[]\n",
    "    y=[]\n",
    "    e=[]\n",
    "    for bina in bins.keys():\n",
    "        x.append(bina)\n",
    "#         print(bina,df[df['instance'].isin(bins[bina])][col])\n",
    "        y.append(np.mean(df[df['instance'].isin(bins[bina])][col]))\n",
    "        \n",
    "        e.append((np.std(df[df['instance'].isin(bins[bina])][col])))\n",
    "#     plt.plot(x,y,label=col)\n",
    "# plot it!\n",
    "    upperbound=[y[i]+e[i] for i in range(len(y))]\n",
    "    lowerbound=[y[i]-e[i] for i in range(len(y))]\n",
    "#     print(lowerbound,upperbound)\n",
    "    ax.plot(x, y, lw=2, label=col)\n",
    "\n",
    "    ax.set_title(\"Mean number of assignments compared to random split\")\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.set_xlabel('mean number of assignments random split')\n",
    "    ax.set_ylabel('mean number of assignments')\n",
    "#     ax.grid()    \n",
    " \n",
    "#     plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
